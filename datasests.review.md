| **Эксперимент (задача)**                                               | **Открытый датасет**                                  | **Почему подходит**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | **Эвристики управления**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | **Метрики оценки**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | **Ссылка на датасет**                                                                                                                                                                                                                          |
| ---------------------------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Детоксикация текста** <br>(генерация без токсичности)                | **RealToxicityPrompts** (Allen AI)                    | Содержит \~100k текстовых фрагментов-промптов из веб-корпуса с различным уровнем токсичности. Предназначен для исследований нейтрализации токсичных продолжений модели и сравнения методов детоксикации.                                                                                                                                                                                                                                                                                                                                                                      | - Фильтрация или штрафование токсичных слов при декодировании (отсеивать продолжения с высокой токсичностью).<br>- Управление генерацией с помощью классификатора токсичности (например, FUDGE-классификатор оценивает частичное продолжение и направляет модель к низкой токсичности).<br>- Метод **DExperts**: использовать “экспертную” LM на нетоксичных данных и “анти-эксперт” на токсичных для сдвига вероятностей в сторону нейтральной речи. <br>- Наивный подход: сгенерировать несколько вариантов и выбрать нетоксичный большинством голосов (по совокупной оценке токсичности).                                                                                                                                                                                                                                                                                                                | - Доля сгенерированных текстов, классифицированных как токсичные (ниже лучше) – оценивается внешним моделью вроде Perspective API.<br>- Средний *toxicity score* по генерациям (мягкая метрика токсичности).<br>- Сохранение связности и смысловой корректности (например, перплексия по языковой модели для флуентности).                                                                                                                                                                                                                                                                                                                                                                                                                      | **HuggingFace:** `allenai/real-toxicity-prompts`                                                                                                                                                                                               |
| **Включение ключевых слов** <br>(генерация по заданным концептам)      | **CommonGen**                                         | Benchmark-датасет для контролируемой генерации с заданным набором ключевых слов (концептов). Модель должна сгенерировать осмысленное предложение, употребив **все** заданные слова. Содержит \~30 тыс. наборов концептов и \~50 тыс. целевых предложений, что позволяет сопоставимо оценивать методы включения обязательных слов.                                                                                                                                                                                                                                             | - Жёсткие лексические ограничения при декодировании (не завершая генерацию, пока не вставлены все обязательные слова).<br>- Генерация нескольких кандидатов и отбор тех, где присутствуют все требуемые ключевые слова (наивное многократное прогон и выбор лучшего).<br>- Управление через дискриминатор: модель-классификатор предсказывает, остались ли неупомянутые концепты, и влияет на выбор следующего слова (как в FUDGE для включения заданных слов).<br>- Пост-правка: добавление пропущенных слов эвристически, если модель их упустила.                                                                                                                                                                                                                                                                                                                                                        | - **Coverage**: процент случаев, когда все заданные слова присутствуют в сгенерированном тексте (важнейший критерий успешности).<br>- Качество текста по совпадению с эталонными описаниями: метрики BLEU, ROUGE, METEOR на CommonGen дают объективную оценку связности и правильности предложения.<br>- Дополнительно оценивают связность/грамматичность (например, human evaluation) и разнообразие формулировок при включении одних и тех же концептов.                                                                                                                                                                                                                                                                                      | **HuggingFace:** `GEM/common_gen`                                                                                                                                                                                                              |
| **Генерация с цитатами** <br>(вставка ссылок на источники)             | **HAGRID** (Attribution QA)                           | Датасет для *верифицируемой* генерации: ответы на вопросы со ссылками на источники. Содержит \~1.9k информационных вопросов, каждому соответствует один или несколько ответов с **цитированием** доказательных отрывков. Подходит для задачи, аналогичной вставке ссылок: модель должна встроить ссылки на факты при генерации ответа.                                                                                                                                                                                                                                        | - Встроить шаблоны ссылок в процесс генерации: например, требовать наличие конструкции “\[№]” в тексте (обозначающей цитату) и принудительно генерировать её на этапах вывода.<br>- Использовать контроллер-классификатор атрибуции: например, модель, предсказывающая по черновому ответу наличие поддерживающих источников, и отклонять/видоизменять продолжения без цитат (по аналогии с FUDGE, на основе признака «есть ссылка»).<br>- Наивный подход: двухшаговая генерация – сначала сгенерировать развернутый ответ, затем автоматически вставить ссылки на проверенные факты (например, постпроцессингом добавить \[1], \[2] после предложений, основанных на источнике).<br>- DExperts-подход: комбинация эксперта (стиль текстов с цитатами, например научных) и анти-эксперта (текст без ссылок) для склонения модели к стилю с цитированием.                                                    | - **Informativeness** (информативность): насколько полно и корректно ответил на вопрос. В HAGRID это оценивается человеком, но автоматически можно применять точность ответа (EM/F1 по известному правильному ответу, если имеется) или сравнение с эталонным развернутым ответом (BLEU/ROUGE).<br>- **Attributability** (атрибутированность): степень, в которой утверждения ответа подкреплены ссылками на источник. Измеряется долей утверждений, для которых указана правильная цитата, или числом цитат из релевантных документов в ответе.<br>- Дополнительно: доля ответов, содержащих хотя бы одну ссылку; точность ссылок (релевантны ли источники) и читаемость/связность ответа в целом (чтобы контроль не ухудшил качество текста). | **HuggingFace:** `miracl/hagrid` (содержит данные и скрипт загрузки)                                                                                                                                                                           |
| **Комбинированные ограничения** <br>(несколько атрибутов одновременно) | **IMDb + OpeNER + SenTube** <br>(объединённый корпус) | Для этой задачи берётся мультиатрибутный датасет, где каждый текст помечен сразу несколькими свойствами. Например, совмещённый набор отзывов о фильмах, отелях и товарах с метками **тематики** (domain) и **тональности** (sentiment). Модель учится генерировать текст на заданную тему (например, фильм vs. отель) и с заданным стилем/тональностью (позитивный vs. негативный отзыв) – это аналогично одновременному контролю нескольких аспектов (содержания и стиля). Такой датасет позволяет количественно сравнить методы по каждому атрибуту отдельно и в сочетании. | - Каскадная генерация: разбиение на подзадачи – сначала генерировать черновик по теме, затем перефразировать его под требуемую тональность (или наоборот).<br>- Одновременное управление двумя контроллерами: в методе FUDGE можно обучить два классификатора (темы и тональности) и во время декодирования комбинировать их вероятности (например, умножать оценки) чтобы направлять текст удовлетворять **обоим** условиям.<br>- DExperts для двух атрибутов: можно задействовать двух экспертов (например, один – “позитивный стиль”, другой – слова по конкретной теме) и анти-экспертов противоположного эффекта, регулируя вклад каждого эксперта в логиты модели.<br>- Наивный подход: перебор вариантов – сгенерировать множество продолжений, затем отобрать те, которые удовлетворяют всем заданным критериям (например, классификатор определил верную тему *и* верную тональность у кандидата). | - **Accuracy (sentiment)**: доля текстов, в которых эмоциональная окраска совпадает с целевой (по модели-сентимент-анализатору или по человеческой оценке).<br>- **Accuracy (topic)**: доля текстов, где тема правильно отражена (определяется либо классификатором темы, либо наличием характерных слов тематики).<br>- Баланс между атрибутами: можно измерять, сколько выводов правильно по одному атрибуту, но ошибочны по другому (для анализа ошибок методов).<br>- Общие метрики качества текста: перплексия для беглости, Dist-1/2 для разнообразия лексики, средняя длина предложений и др. (важно, чтобы многократные ограничения не ухудшили связность).                                                                             | IMDb: **HuggingFace** `stanfordnlp/imdb` (сентимент отзывы);<br>OpeNER: *запрос по проекту OpeNER (отзывы отелей)*;<br>SenTube: *скачать комментарии с Youtube с сайта проекта SenTube*. (Данные объединяются для мультиатрибутного обучения.) |
